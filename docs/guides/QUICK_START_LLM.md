# üîê Guide rapide : Configurer OVH AI Endpoints

## üìù √âtape 1 : Obtenir un token OVH AI

1. Aller sur https://endpoints.ai.cloud.ovh.net/
2. Se connecter avec votre compte OVH
3. Cr√©er un nouveau endpoint ou utiliser un existant
4. R√©cup√©rer :
   - **URL de l'endpoint** : `https://xxx.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1`
   - **Token API** : Le token d'authentification

## üìã √âtape 2 : Mettre √† jour le fichier .env

Ouvrir le fichier `backend/.env` et configurer :

```dotenv
# LLM Configuration - OVH AI Endpoints
LLM_PROVIDER=ovh
OVH_API_KEY=votre_token_ovh_ici
OVH_ENDPOINT_URL=https://xxx.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
OVH_MODEL=Mixtral-8x22B-Instruct-v0.1

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
```

**Exemple complet du fichier `.env` :**

```dotenv
# LLM Configuration - OVH AI Endpoints
LLM_PROVIDER=ovh
OVH_API_KEY=eyJhbGciOiJSUzI1NiIsInR5...
OVH_ENDPOINT_URL=https://mixtral-8x22b.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
OVH_MODEL=Mixtral-8x22B-Instruct-v0.1

# Optional - Other settings
ENVIRONMENT=production
LOG_LEVEL=INFO
```

## ‚úÖ √âtape 3 : Tester la configuration

### Option A : Via l'interface Settings

1. Aller sur `http://localhost:8000/dashboard/settings.html`
2. Ouvrir la section **"LLM Configuration"**
3. Remplir les champs :
   - **Provider** : OVH
   - **OVH API Key** : Votre token
   - **OVH Endpoint URL** : L'URL de votre endpoint
   - **OVH Model** : Le nom du mod√®le (ex: Mixtral-8x22B-Instruct-v0.1)
4. Cliquer sur **"Save Configuration"**

### Option B : Test via API

```bash
curl -X GET "http://localhost:8000/api/llm-config" | jq
```

**R√©ponse attendue :**
```json
{
  "provider": "ovh",
  "api_key_set": true,
  "available": true,
  "llm_provider": "ovh",
  "status": "configured"
}
```

## üöÄ √âtape 4 : Utiliser les fonctionnalit√©s LLM

Une fois configur√©, les fonctionnalit√©s suivantes sont disponibles :

### Dashboard Analytics - "What's Happening"
- G√©n√©ration automatique d'insights √† partir des posts collect√©s
- Cliquer sur "Generate Insights" pour lancer l'analyse

### Improvements Opportunities
- Analyse automatique des pain points
- Recommandations d'am√©liorations produit
- Filtrage par produit avec analyse contextuelle

## üí° Mod√®les OVH AI disponibles

| Mod√®le | Description | Utilisation |
|--------|-------------|-------------|
| **Mixtral-8x22B-Instruct-v0.1** | Mod√®le puissant pour l'analyse | Recommand√© pour analyses complexes |
| **Llama-3.1-70B-Instruct** | Mod√®le Llama optimis√© | Bonne alternative |
| **Mistral-7B-Instruct** | Mod√®le l√©ger | Pour tests et usage mod√©r√© |

## üõ°Ô∏è Bonnes pratiques

### ‚úÖ √Ä FAIRE

```python
# 1. Toujours v√©rifier la disponibilit√© du LLM
from backend.app.database import pg_get_config

ovh_key = pg_get_config('OVH_API_KEY')
if not ovh_key:
    logger.warning("OVH API key not configured")

# 2. Utiliser les timeouts
response = await client.chat.completions.create(
    model=model_name,
    messages=messages,
    timeout=30  # 30 secondes max
)

# 3. Logger sans exposer les secrets
logger.info(f"Using OVH endpoint: {endpoint_url[:30]}...")
```

### ‚ùå √Ä NE PAS FAIRE

```python
# ‚ùå Ne jamais logger le token complet
logger.info(f"Token: {ovh_token}")

# ‚ùå Ne pas faire d'appels sans limite de temps
response = await client.chat.completions.create(...)  # Pas de timeout
```

## üÜò D√©pannage

### Erreur : "OVH endpoint not configured"

**V√©rifier :**
1. `OVH_API_KEY` est d√©fini dans `.env` ou via l'interface Settings
2. `OVH_ENDPOINT_URL` est d√©fini et correct
3. Le serveur a √©t√© red√©marr√© apr√®s modification du `.env`

### Erreur : "Authentication failed"

**Solutions :**
1. V√©rifier que le token est valide (pas expir√©)
2. V√©rifier que le token a les permissions n√©cessaires
3. R√©g√©n√©rer le token sur https://endpoints.ai.cloud.ovh.net/

### Erreur : "Model not found"

**Solutions :**
1. V√©rifier le nom exact du mod√®le sur votre endpoint OVH
2. Mettre √† jour `OVH_MODEL` avec le bon nom

## ‚úÖ Checklist finale

- [ ] Token OVH AI obtenu depuis endpoints.ai.cloud.ovh.net
- [ ] `.env` configur√© avec OVH_API_KEY, OVH_ENDPOINT_URL, OVH_MODEL
- [ ] LLM_PROVIDER=ovh d√©fini
- [ ] Test via API ou interface r√©ussi
- [ ] Fonctionnalit√©s LLM op√©rationnelles (Insights, Improvements)

---

**Pr√™t √† utiliser !** üöÄ

Votre application utilise maintenant **OVH AI Endpoints** pour :
- G√©n√©rer des insights automatiques
- Analyser les probl√®mes clients
- Recommander des am√©liorations produit

**Avantage :** Infrastructure OVH interne, pas de d√©pendance externe, donn√©es s√©curis√©es.
