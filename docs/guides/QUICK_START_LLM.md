# üîê Guide rapide : Utiliser votre nouvelle cl√© OpenAI

## üìù √âtape 1 : Obtenir une nouvelle cl√©

1. Aller sur https://platform.openai.com/api-keys
2. Cliquer sur **"+ Create new secret key"**
3. Donner un nom (ex: "OVH-Complaints-Tracker-2026")
4. Copier la cl√© (elle commence par `sk-proj-...`)
5. ‚ö†Ô∏è **Important** : Vous ne pourrez plus la revoir apr√®s !

## üìã √âtape 2 : Mettre √† jour le fichier .env

Ouvrir le fichier `backend/.env` et remplacer :

```dotenv
# AVANT
OPENAI_API_KEY=your_openai_api_key_here

# APR√àS  
OPENAI_API_KEY=sk-proj-VOTRE_NOUVELLE_CLE_ICI
```

**Exemple complet du fichier `.env` :**

```dotenv
# LLM Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-1a2b3c4d5e6f7g8h9i0j...

# Optional API Keys
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
TRUSTPILOT_API_KEY=
GITHUB_TOKEN=

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
```

## ‚úÖ √âtape 3 : Tester la configuration

### Option A : Test complet (recommand√©)

```bash
cd backend
python test_llm_config.py
```

Ce script va :
- ‚úÖ Valider la configuration
- ‚úÖ Tester le masquage des cl√©s
- ‚úÖ Initialiser le client
- ‚úÖ Faire un appel API de test (co√ªt ~$0.0001)

**Sortie attendue :**
```
============================================================
 LLM CONFIGURATION TEST SUITE
============================================================

TEST 1: Configuration Validation
‚úÖ Configuration is valid

Configuration summary:
==================================================
üîß APPLICATION CONFIGURATION
==================================================
Environment: development
LLM Provider: openai

üîë API Keys Status:
  ‚úÖ openai      : sk-proj-...abc123
  ...

TEST 4: LLM API Call (Simple Test)
‚úÖ API call successful!
   Response: Hello
   Model used: gpt-4o-mini

Result: 4/4 tests passed
```

### Option B : Test rapide (sans appel API)

```bash
cd C:\Users\tlorinea\Documents\Documents\Documents\Projets\VibeCoding\ovh-complaints-tracker
python -c "from backend.app.config import config, validate_config_on_startup; result = validate_config_on_startup(); print('Valid:', result['valid'])"
```

## üöÄ √âtape 4 : Red√©marrer le serveur

```bash
cd C:\Users\tlorinea\Documents\Documents\Documents\Projets\VibeCoding\ovh-complaints-tracker

# D√©finir le PYTHONPATH et d√©marrer
$env:PYTHONPATH = (Get-Location).Path
python -m uvicorn backend.app.main:app --port 9000 --reload
```

**Logs attendus au d√©marrage :**
```
============================================================
 STARTING OVH COMPLAINTS TRACKER
============================================================

[SECURITY] Validating configuration...
[OK] Configuration validated successfully

[DATABASE] Initializing...
[OK] Database initialized

[SCHEDULER] Starting auto-scrape job (every 3 hours)...
[OK] Scheduler started

============================================================
 APPLICATION READY!
============================================================
```

## üí° Exemples d'utilisation dans le code

### Exemple 1 : Analyse de sentiment avec LLM

Cr√©er `backend/app/analysis/llm_sentiment.py` :

```python
from ..config import get_llm_client
import logging

logger = logging.getLogger(__name__)

def analyze_sentiment_with_llm(text: str) -> dict:
    """Analyze sentiment using LLM (more accurate than VADER)."""
    try:
        client = get_llm_client()
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a sentiment analyzer. Respond with only: POSITIVE, NEGATIVE, or NEUTRAL"
                },
                {
                    "role": "user",
                    "content": f"Analyze sentiment of: {text[:500]}"
                }
            ],
            max_tokens=10,
            temperature=0
        )
        
        sentiment = response.choices[0].message.content.strip().upper()
        
        # Convert to score
        score_map = {"POSITIVE": 0.8, "NEGATIVE": -0.8, "NEUTRAL": 0.0}
        score = score_map.get(sentiment, 0.0)
        
        return {
            "label": sentiment.lower(),
            "score": score,
            "method": "llm"
        }
        
    except Exception as e:
        logger.error(f"LLM sentiment analysis failed: {type(e).__name__}")
        # Fallback to VADER
        from . import sentiment
        return sentiment.analyze(text)
```

### Exemple 2 : Extraction de mots-cl√©s

```python
def extract_keywords_with_llm(text: str, max_keywords: int = 5) -> list:
    """Extract key topics from customer feedback."""
    try:
        client = get_llm_client()
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"Extract {max_keywords} key topics. Return as comma-separated list."
                },
                {
                    "role": "user",
                    "content": text[:1000]
                }
            ],
            max_tokens=50
        )
        
        keywords_text = response.choices[0].message.content
        keywords = [k.strip() for k in keywords_text.split(",")]
        
        return keywords[:max_keywords]
        
    except Exception as e:
        logger.error(f"Keyword extraction failed: {e}")
        return []
```

### Exemple 3 : R√©sum√© de feedback

```python
def summarize_feedback(feedbacks: list, max_length: int = 200) -> str:
    """Summarize multiple customer feedbacks."""
    try:
        client = get_llm_client()
        
        # Combine feedback texts
        combined = "\n".join([f["content"][:200] for f in feedbacks[:10]])
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"Summarize customer complaints in {max_length} characters max."
                },
                {
                    "role": "user",
                    "content": combined
                }
            ],
            max_tokens=100
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        logger.error(f"Summarization failed: {e}")
        return "Unable to generate summary"
```

## üõ°Ô∏è Bonnes pratiques

### ‚úÖ √Ä FAIRE

```python
# 1. Toujours g√©rer les exceptions
try:
    client = get_llm_client()
    response = client.chat.completions.create(...)
except ValueError as e:
    logger.error(f"Config error: {e}")
except Exception as e:
    logger.error(f"API error: {type(e).__name__}")

# 2. Limiter les tokens pour contr√¥ler les co√ªts
response = client.chat.completions.create(
    model="gpt-4o-mini",  # Mod√®le le moins cher
    max_tokens=100,  # Limiter la r√©ponse
    ...
)

# 3. Logger avec masquage
logger.info(f"Using API key: {config.mask_api_key(config.OPENAI_API_KEY)}")

# 4. Avoir un fallback
try:
    result = analyze_with_llm(text)
except:
    result = analyze_with_vader(text)  # Fallback local
```

### ‚ùå √Ä NE PAS FAIRE

```python
# ‚ùå Ne jamais logger la cl√© compl√®te
logger.info(f"API Key: {config.OPENAI_API_KEY}")

# ‚ùå Ne pas faire d'appels sans limite
for item in huge_list:  # Peut co√ªter cher !
    llm_analyze(item)

# ‚ùå Ne pas ignorer les erreurs silencieusement
try:
    result = llm_call()
except:
    pass  # ‚ùå Mauvais !
```

## üìä Surveillance des co√ªts

### Sur OpenAI Dashboard

1. Aller sur https://platform.openai.com/usage
2. V√©rifier :
   - **Usage today** : Combien de $ utilis√©s aujourd'hui
   - **Requests** : Nombre d'appels API
   - **Tokens** : Nombre de tokens consomm√©s

### D√©finir une limite de d√©penses

1. Aller sur https://platform.openai.com/account/limits
2. D√©finir **Monthly budget** (ex: $10/mois)
3. Activer les alertes email

### Estimer les co√ªts

**gpt-4o-mini** (recommand√©) :
- Input : $0.150 / 1M tokens
- Output : $0.600 / 1M tokens

**Exemple** : 
- Analyser 1000 feedbacks de 200 caract√®res (~50 tokens)
- = 50,000 tokens input + 10,000 tokens output
- = ~$0.01 (1 centime)

## üîÑ Changer de provider LLM

### Passer √† Anthropic (Claude)

```dotenv
# Dans .env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-api-...
```

Le code reste le m√™me gr√¢ce √† `get_llm_client()` !

### Passer √† Google AI

```dotenv
LLM_PROVIDER=google
GOOGLE_API_KEY=AIza...
```

## üÜò D√©pannage

### Erreur : "Invalid API key"

```bash
# V√©rifier que la cl√© est bien d√©finie
python -c "from backend.app.config import config; print(config.mask_api_key(config.OPENAI_API_KEY))"
```

Si affiche `your_...here`, la cl√© n'est pas charg√©e.

**Solutions :**
1. V√©rifier que `.env` est bien dans `backend/`
2. Pas d'espace avant/apr√®s `=`
3. Red√©marrer le serveur apr√®s modification

### Erreur : "Rate limit exceeded"

Vous avez d√©pass√© la limite de requ√™tes/minute.

**Solutions :**
- Ajouter `time.sleep(1)` entre les appels
- R√©duire le nombre d'appels simultan√©s
- Upgrader votre plan OpenAI

### Erreur : "Insufficient quota"

Votre compte OpenAI n'a plus de cr√©dit.

**Solutions :**
- Ajouter une carte de paiement : https://platform.openai.com/account/billing
- V√©rifier les limites : https://platform.openai.com/account/limits

## ‚úÖ Checklist finale

- [ ] Nouvelle cl√© OpenAI g√©n√©r√©e
- [ ] `.env` mis √† jour avec la nouvelle cl√©  
- [ ] Test `python test_llm_config.py` r√©ussi
- [ ] Serveur red√©marr√© avec succ√®s
- [ ] Logs de validation apparaissent au d√©marrage
- [ ] Budget/alertes configur√©s sur OpenAI
- [ ] Ancienne cl√© r√©voqu√©e ‚úÖ (d√©j√† fait)

---

**Pr√™t √† utiliser !** üöÄ

Votre application peut maintenant :
- Analyser le sentiment avec LLM (plus pr√©cis)
- Extraire des mots-cl√©s automatiquement
- G√©n√©rer des r√©sum√©s de feedback
- Et tout autre traitement NLP avanc√©

**Co√ªt estim√© :** ~$0.01-0.05 par 1000 feedbacks analys√©s
