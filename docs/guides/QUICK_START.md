# üöÄ Guide de D√©marrage Rapide - OVH Customer Feedbacks Tracker

Guide complet pour d√©marrer et utiliser l'application, du d√©butant √† l'utilisateur avanc√©.

> **Note:** Ce projet a √©t√© d√©velopp√© **100% avec VibeCoding** (Cursor AI).

---

## ‚úÖ Pr√©requis

1. **Python 3.11 ou sup√©rieur** install√©
2. **Connexion Internet** (pour t√©l√©charger les d√©pendances)
3. **Navigateur web** (Chrome, Firefox, Edge, etc.)

### V√©rifier Python

**Windows :**
```powershell
python --version  # Doit afficher Python 3.11.x ou sup√©rieur
```

**Linux/Mac :**
```bash
python3 --version
```

**Si Python n'est pas install√© :**
- T√©l√©charger depuis : https://www.python.org/downloads/
- ‚ö†Ô∏è **Important** : Cocher "Add Python to PATH" lors de l'installation

---

## üì¶ Installation (5 minutes)

### √âtape 1 : Installer les d√©pendances

```bash
cd backend
pip install -r requirements.txt
```

**Si `pip` ne fonctionne pas :**
- Windows : `python -m pip install -r requirements.txt`
- Linux/Mac : `pip3 install -r requirements.txt`

---

## üöÄ D√©marrer l'application

### Option 1 : Script automatique (RECOMMAND√â)

**Windows :**
```powershell
.\start_server.ps1
```

**Linux/Mac :**
```bash
./start_server.sh
```

### Option 2 : Commande manuelle

```bash
cd backend
python -m uvicorn app.main:app --reload --port 8000
```

**Le serveur d√©marrera sur :** `http://localhost:8000`

---

## üåê Acc√©der √† l'application

1. Ouvrir votre navigateur
2. Aller √† : `http://localhost:8000`
3. Vous devriez voir la page d'accueil

---

## üß™ Tester rapidement

### Test 1 : Voir les posts existants
1. Cliquer sur **"Dashboard Analytics"** dans le menu
2. Vous devriez voir des graphiques et statistiques

### Test 2 : Lancer un scraper
1. Cliquer sur **"Feedbacks Collection"** dans le menu
2. Cliquer sur le bouton **"Scrape Reddit"** (ou un autre)
3. Attendre quelques secondes
4. Vous devriez voir un message de succ√®s

### Test 3 : Voir les logs
1. Cliquer sur **"Scraping Logs"** dans le menu
2. Vous devriez voir l'historique des op√©rations

---

## ‚ùå Probl√®mes courants

### "python n'est pas reconnu"
**Solution :** Python n'est pas dans le PATH
- R√©installer Python en cochant "Add Python to PATH"
- Ou utiliser `py` au lieu de `python` (Windows)

### "pip n'est pas reconnu"
**Solution :** Utiliser `python -m pip` au lieu de `pip`
```bash
python -m pip install -r requirements.txt
```

### "Le port 8000 est d√©j√† utilis√©"
**Solution :** Arr√™ter l'autre application ou changer le port
```bash
python -m uvicorn app.main:app --reload --port 8001
```
Puis aller √† : `http://localhost:8001`

### "Module not found"
**Solution :** R√©installer les d√©pendances
```bash
pip install -r requirements.txt --force-reinstall
```

---

## üîê Configuration des cl√©s API (Optionnel)

Pour utiliser les fonctionnalit√©s LLM et certains scrapers, vous devez configurer les cl√©s API dans `backend/.env` :

```dotenv
# LLM Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# Scrapers API Keys
TRUSTPILOT_API_KEY=
GITHUB_TOKEN=
LINKEDIN_CLIENT_ID=
LINKEDIN_CLIENT_SECRET=
TWITTER_BEARER_TOKEN=
```

üìñ **Guide d√©taill√© pour LLM :** [QUICK_START_LLM.md](QUICK_START_LLM.md)

---

## üìö Documentation compl√®te

- **Guide de test :** [GUIDE_TEST.md](GUIDE_TEST.md)
- **Tests E2E :** [GUIDE_E2E_TESTS.md](GUIDE_E2E_TESTS.md)
- **Configuration API :** [GUIDE_API_KEYS.md](GUIDE_API_KEYS.md)
- **Versioning :** [VERSIONING.md](VERSIONING.md)

---

## üéØ Fonctionnalit√©s principales

### Scraping
- **X/Twitter** : Posts et tweets mentionnant OVH
- **Reddit** : Discussions et commentaires
- **GitHub** : Issues et discussions
- **Stack Overflow** : Questions et r√©ponses
- **Trustpilot** : Avis clients
- **Mastodon** : Posts sur instances Mastodon
- **OVH Forum** : Discussions du forum officiel
- **G2 Crowd** : Avis et √©valuations

### Analytics
- **Dashboard** : Graphiques et statistiques
- **Filtres** : Par source, sentiment, date, langue
- **Recherche** : Recherche textuelle dans tous les posts
- **Export** : Export CSV des donn√©es

### Gestion
- **Backlog** : Sauvegarder des posts importants
- **Logs** : Historique des op√©rations de scraping
- **Jobs** : Suivi des t√¢ches de scraping en cours

---

## üéâ Tout est pr√™t !

Votre application est maintenant :
- ‚úÖ **S√©curis√©e** (score 85/100)
- ‚úÖ **Optimis√©e** (index de base de donn√©es)
- ‚úÖ **Document√©e** (guides complets)
- ‚úÖ **Testable** (scripts de test inclus)
- ‚úÖ **Maintenable** (code structur√©, logs organis√©s)

**Bon d√©veloppement ! üöÄ**

