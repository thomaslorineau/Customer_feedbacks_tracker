# Guide: Contourner les Protections Anti-Scraping

Ce guide explique les techniques l√©gitimes pour am√©liorer la fiabilit√© des scrapers face aux protections anti-bot.

## ‚ö†Ô∏è Important : √âthique et L√©galit√©

- **Respectez les ToS** : V√©rifiez toujours les conditions d'utilisation
- **Respectez robots.txt** : Consultez `/robots.txt` avant de scraper
- **Rate Limiting** : Ne surchargez pas les serveurs
- **Donn√©es publiques uniquement** : Ne scrapez que du contenu public
- **Utilisez les APIs officielles** quand disponibles

## üõ°Ô∏è Techniques Impl√©ment√©es

### 1. Headers R√©alistes

Les scrapers utilisent maintenant des headers de navigateur r√©alistes :

```python
from app.scraper.anti_bot_helpers import get_realistic_headers

headers = get_realistic_headers(referer="https://example.com")
```

**Inclut :**
- User-Agent rotatif (pool de User-Agents r√©alistes)
- Headers complets (Accept, Accept-Language, Accept-Encoding, etc.)
- Sec-Fetch-* headers (comportement navigateur moderne)
- Referer appropri√©

### 2. D√©lais Humains

Simulation de comportement humain avec d√©lais al√©atoires :

```python
from app.scraper.anti_bot_helpers import human_like_delay

human_like_delay(min_seconds=1.0, max_seconds=3.0)
```

**Avantages :**
- Distribution normale (plus r√©aliste)
- √âvite les patterns d√©tectables
- Respecte les serveurs

### 3. Sessions Stealth

Cr√©ation de sessions avec configuration optimale :

```python
from app.scraper.anti_bot_helpers import create_stealth_session

session = create_stealth_session()
```

**Caract√©ristiques :**
- Retry strategy intelligente
- Headers r√©alistes par d√©faut
- Gestion des connexions optimis√©e

### 4. Simulation de Comportement Humain

Visite de la page principale avant la requ√™te cible :

```python
from app.scraper.anti_bot_helpers import simulate_human_behavior

simulate_human_behavior(session, target_url)
```

**Comportement :**
- Visite la page d'accueil d'abord
- Ajoute des d√©lais naturels
- D√©finit le Referer correctement

## üöÄ Techniques Avanc√©es

### 5. Selenium/Playwright (Pour sites JavaScript)

Pour les sites avec protection Cloudflare ou JavaScript lourd :

```python
from app.scraper.selenium_helper import scrape_with_selenium, scrape_with_playwright

# Avec Selenium
html = scrape_with_selenium(url, wait_selector=".content", timeout=10)

# Avec Playwright (recommand√©)
html = scrape_with_playwright(url, wait_selector=".content", timeout=10000)
```

**Installation :**
```bash
# Selenium
pip install selenium
# T√©l√©charger ChromeDriver et l'ajouter au PATH

# Playwright (recommand√©)
pip install playwright
playwright install chromium
```

**Avantages :**
- Ex√©cute le JavaScript
- Contourne Cloudflare
- Comportement de navigateur r√©el

**Inconv√©nients :**
- Plus lent
- Consomme plus de ressources
- N√©cessite un navigateur

### 6. Rotation de Proxies

Utilisation de proxies pour √©viter les blocages IP :

```python
from app.scraper.anti_bot_helpers import rotate_proxy

proxies = rotate_proxy(proxy_list=[
    'http://proxy1:8080',
    'http://proxy2:8080'
])

session.get(url, proxies=proxies)
```

**Types de proxies :**
- **Residential** : IPs r√©sidentielles (meilleur, plus cher)
- **Datacenter** : IPs de datacenter (moins cher, plus d√©tectable)
- **Rotating** : Rotation automatique

**Services recommand√©s :**
- Bright Data (ex-Luminati)
- Smartproxy
- Oxylabs

### 7. Cookies et Sessions

Maintenir des sessions persistantes :

```python
from app.scraper.anti_bot_helpers import add_cookies_from_browser

# Extraire les cookies depuis un navigateur r√©el
cookies = {
    'session_id': 'abc123',
    'csrf_token': 'xyz789'
}
add_cookies_from_browser(session, cookies)
```

## üìã Strat√©gies par Type de Protection

### Cloudflare

**Solution :** Playwright avec options stealth
```python
html = scrape_with_playwright(url)
```

### Rate Limiting (429)

**Solution :** Exponential backoff + rotation User-Agent
```python
from app.scraper.anti_bot_helpers import exponential_backoff_delay

delay = exponential_backoff_delay(attempt=2)
time.sleep(delay)
```

### JavaScript Required

**Solution :** Selenium ou Playwright
```python
html = scrape_with_playwright(url, wait_selector=".main-content")
```

### CAPTCHA

**Solutions :**
1. **2Captcha / AntiCaptcha** : Services de r√©solution
2. **Playwright avec extensions** : R√©solution automatique
3. **√âviter** : Utiliser des APIs ou sources alternatives

### IP Blocking

**Solutions :**
1. **Proxies rotatifs** : Rotation d'IPs
2. **VPN** : Changer d'IP r√©guli√®rement
3. **Rate limiting** : R√©duire la fr√©quence

## üîß Configuration

### Variables d'Environnement

```bash
# Proxies (optionnel)
PROXY_LIST=http://proxy1:8080,http://proxy2:8080

# User-Agents personnalis√©s (optionnel)
CUSTOM_USER_AGENTS=...

# D√©lais personnalis√©s (optionnel)
SCRAPER_MIN_DELAY=1.0
SCRAPER_MAX_DELAY=3.0
```

### Utilisation dans les Scrapers

Les scrapers utilisent automatiquement ces techniques :

```python
# OVH Forum
from app.scraper import ovh_forum
posts = ovh_forum.scrape_ovh_forum(query="OVH", limit=50)

# G2 Crowd
from app.scraper import g2_crowd
reviews = g2_crowd.scrape_g2_crowd(query="OVH", limit=50)
```

## ‚ö° Meilleures Pratiques

1. **Commencez simple** : Utilisez requests avec headers r√©alistes
2. **Ajoutez des d√©lais** : Toujours entre les requ√™tes
3. **Respectez robots.txt** : V√©rifiez avant de scraper
4. **Utilisez les APIs** : Pr√©f√©rez les APIs officielles
5. **Cachez les r√©sultats** : √âvitez de re-scraper inutilement
6. **Surveillez les erreurs** : Loggez les 403/503 pour ajuster
7. **Testez r√©guli√®rement** : Les protections √©voluent

## üéØ Solutions par Site

### OVH Forum
- ‚úÖ Headers r√©alistes
- ‚úÖ D√©lais humains
- ‚ö†Ô∏è Peut n√©cessiter Selenium si protection renforc√©e

### G2 Crowd
- ‚úÖ Headers r√©alistes
- ‚úÖ D√©lais humains
- ‚ö†Ô∏è Protection forte - peut n√©cessiter proxies ou Selenium
- üí° Alternative : Utiliser G2 API si disponible

### Mastodon
- ‚úÖ API publique - pas de protection
- ‚úÖ Fonctionne bien avec requests simple

## üìö Ressources

- [Selenium Documentation](https://selenium-python.readthedocs.io/)
- [Playwright Documentation](https://playwright.dev/python/)
- [Scrapy Middleware](https://docs.scrapy.org/en/latest/topics/spider-middleware.html)
- [HTTP Headers Reference](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers)

## ‚öñÔ∏è Avertissement L√©gal

Ce guide fournit des techniques techniques. Vous √™tes responsable de :
- Respecter les ToS de chaque site
- Respecter les lois locales
- Ne pas surcharger les serveurs
- Utiliser les donn√©es de mani√®re √©thique

**En cas de doute, utilisez les APIs officielles ou contactez le propri√©taire du site.**


